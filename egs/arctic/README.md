# Parallel one-to-one seq2seq VC recipe using the CMU ARCTIC dataset

We provide two recipes:

- `vc1`: autoregressive (AR) seq2seq modeling, reproducing [1]
- `vc2`: non-autoregressive (non-AR) seq2seq modeling, reproducing [2, 3]

[1] W.-C. Huang, T. Hayashi, Y.-C. Wu, H. Kameoka, and T. Toda, “Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining,” in Proc. Interspeech, 2020, pp. 4676–4680.
[2] T. Hayashi, W.-C. Huang, K. Kobayashi, and T. Toda, “Non- Autoregressive Sequence-To-Sequence Voice Conversion,” in Proc. ICASSP, 2021, pp. 7068–7072.
[3] W.-C. Huang, K. Kobayashi, and T. Toda, “AAS-VC: On the Generalization Ability of Automatic Alignment Search based Non-autoregressive Sequence-to-sequence Voice Conversion,” submitted to ICASSP 2024